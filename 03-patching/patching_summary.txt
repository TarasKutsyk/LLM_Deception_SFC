=== Semantic Causal Patching Analysis Results ===


Group: truth_related
  Top Attention Layers:
    Layer 11: 0.0253
    Layer 0: 0.0250
    Layer 1: 0.0218
  Top MLP Layers:
    Layer 5: 0.0415
    Layer 4: 0.0314
    Layer 0: 0.0283
  Average Attention Effect: 0.0066
  Average MLP Effect: 0.0105

Group: lie_related
  Top Attention Layers:
    Layer 11: 0.0253
    Layer 0: 0.0250
    Layer 1: 0.0218
  Top MLP Layers:
    Layer 5: 0.0415
    Layer 4: 0.0314
    Layer 0: 0.0283
  Average Attention Effect: 0.0066
  Average MLP Effect: 0.0105

Group: consequence
  Top Attention Layers:
    Layer 9: 0.0356
    Layer 12: 0.0339
    Layer 11: 0.0304
  Top MLP Layers:
    Layer 1: 0.0397
    Layer 12: 0.0342
    Layer 11: 0.0284
  Average Attention Effect: 0.0104
  Average MLP Effect: 0.0100

Group: intent
  Top Attention Layers:
    Layer 41: 0.0000
    Layer 40: 0.0000
    Layer 39: 0.0000
  Top MLP Layers:
    Layer 41: 0.0000
    Layer 40: 0.0000
    Layer 39: 0.0000
  Average Attention Effect: 0.0000
  Average MLP Effect: 0.0000

Group: question
  Top Attention Layers:
    Layer 11: 0.0697
    Layer 20: 0.0655
    Layer 21: 0.0598
  Top MLP Layers:
    Layer 7: 0.1059
    Layer 10: 0.0871
    Layer 3: 0.0847
  Average Attention Effect: 0.0213
  Average MLP Effect: 0.0288

Group: answer
  Top Attention Layers:
    Layer 2: 0.0284
    Layer 10: 0.0268
    Layer 11: 0.0234
  Top MLP Layers:
    Layer 10: 0.0304
    Layer 12: 0.0284
    Layer 13: 0.0270
  Average Attention Effect: 0.0073
  Average MLP Effect: 0.0086

Group: user
  Top Attention Layers:
    Layer 41: 0.0000
    Layer 40: 0.0000
    Layer 39: 0.0000
  Top MLP Layers:
    Layer 41: 0.0000
    Layer 40: 0.0000
    Layer 39: 0.0000
  Average Attention Effect: 0.0000
  Average MLP Effect: 0.0000