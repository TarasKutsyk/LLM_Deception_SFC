=== Semantic Causal Patching Analysis Results ===


Group: truth_related
  Top Attention Layers:
    Layer 3: 0.1035
    Layer 7: 0.1035
    Layer 9: 0.1035
  Top MLP Layers:
    Layer 6: 0.1729
    Layer 5: 0.1377
    Layer 2: 0.1377
  Average Attention Effect: 0.0213
  Average MLP Effect: 0.0287

Group: lie_related
  Top Attention Layers:
    Layer 3: 0.1035
    Layer 7: 0.1035
    Layer 9: 0.1035
  Top MLP Layers:
    Layer 6: 0.1729
    Layer 5: 0.1377
    Layer 2: 0.1377
  Average Attention Effect: 0.0213
  Average MLP Effect: 0.0287

Group: consequence
  Top Attention Layers:
    Layer 7: 0.1377
    Layer 11: 0.1377
    Layer 9: 0.1377
  Top MLP Layers:
    Layer 7: 0.1377
    Layer 16: 0.1035
    Layer 5: 0.1035
  Average Attention Effect: 0.0287
  Average MLP Effect: 0.0336

Group: intent
  Top Attention Layers:
    Layer 41: 0.0000
    Layer 40: 0.0000
    Layer 39: 0.0000
  Top MLP Layers:
    Layer 41: 0.0000
    Layer 40: 0.0000
    Layer 39: 0.0000
  Average Attention Effect: 0.0000
  Average MLP Effect: 0.0000

Group: question
  Top Attention Layers:
    Layer 4: 0.1729
    Layer 18: 0.1729
    Layer 14: 0.1729
  Top MLP Layers:
    Layer 4: 0.2754
    Layer 17: 0.2754
    Layer 18: 0.2070
  Average Attention Effect: 0.0460
  Average MLP Effect: 0.0608

Group: answer
  Top Attention Layers:
    Layer 10: 0.1035
    Layer 19: 0.1035
    Layer 15: 0.1035
  Top MLP Layers:
    Layer 11: 0.1035
    Layer 6: 0.0688
    Layer 13: 0.0688
  Average Attention Effect: 0.0148
  Average MLP Effect: 0.0107

Group: user
  Top Attention Layers:
    Layer 41: 0.0000
    Layer 40: 0.0000
    Layer 39: 0.0000
  Top MLP Layers:
    Layer 41: 0.0000
    Layer 40: 0.0000
    Layer 39: 0.0000
  Average Attention Effect: 0.0000
  Average MLP Effect: 0.0000