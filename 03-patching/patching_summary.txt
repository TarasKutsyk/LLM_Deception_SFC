=== Semantic Causal Patching Analysis Results ===


Group: truth_related
  Top Attention Layers:
    Layer 14: 0.0422
    Layer 5: 0.0404
    Layer 0: 0.0396
  Top MLP Layers:
    Layer 14: 0.1017
    Layer 12: 0.0892
    Layer 9: 0.0831
  Average Attention Effect: 0.0118
  Average MLP Effect: 0.0232

Group: lie_related
  Top Attention Layers:
    Layer 14: 0.0422
    Layer 5: 0.0404
    Layer 0: 0.0396
  Top MLP Layers:
    Layer 14: 0.1017
    Layer 12: 0.0892
    Layer 9: 0.0831
  Average Attention Effect: 0.0118
  Average MLP Effect: 0.0232

Group: consequence
  Top Attention Layers:
    Layer 16: 0.0742
    Layer 17: 0.0631
    Layer 0: 0.0430
  Top MLP Layers:
    Layer 3: 0.0437
    Layer 10: 0.0389
    Layer 1: 0.0353
  Average Attention Effect: 0.0147
  Average MLP Effect: 0.0110

Group: intent
  Top Attention Layers:
    Layer 41: 0.0000
    Layer 40: 0.0000
    Layer 39: 0.0000
  Top MLP Layers:
    Layer 41: 0.0000
    Layer 40: 0.0000
    Layer 39: 0.0000
  Average Attention Effect: 0.0000
  Average MLP Effect: 0.0000

Group: question
  Top Attention Layers:
    Layer 9: 0.0564
    Layer 10: 0.0531
    Layer 12: 0.0472
  Top MLP Layers:
    Layer 13: 0.1226
    Layer 18: 0.0691
    Layer 7: 0.0690
  Average Attention Effect: 0.0148
  Average MLP Effect: 0.0193

Group: answer
  Top Attention Layers:
    Layer 3: 0.0970
    Layer 6: 0.0762
    Layer 5: 0.0721
  Top MLP Layers:
    Layer 5: 0.0720
    Layer 8: 0.0701
    Layer 2: 0.0699
  Average Attention Effect: 0.0188
  Average MLP Effect: 0.0209

Group: user
  Top Attention Layers:
    Layer 41: 0.0000
    Layer 40: 0.0000
    Layer 39: 0.0000
  Top MLP Layers:
    Layer 41: 0.0000
    Layer 40: 0.0000
    Layer 39: 0.0000
  Average Attention Effect: 0.0000
  Average MLP Effect: 0.0000