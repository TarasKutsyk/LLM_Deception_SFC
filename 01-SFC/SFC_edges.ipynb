{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "qJWpQuM1crPG",
    "outputId": "dd63f30f-2715-40a1-a7ce-61a59e4483bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:7\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab # type: ignore\n",
    "    from google.colab import output\n",
    "    COLAB = True\n",
    "    %pip install sae-lens transformer-lens\n",
    "except:\n",
    "    COLAB = False\n",
    "    from IPython import get_ipython # type: ignore\n",
    "    ipython = get_ipython(); assert ipython is not None\n",
    "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "    ipython.run_line_magic(\"autoreload\", \"2\")\n",
    "\n",
    "# Standard imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import einops\n",
    "from jaxtyping import Float, Int\n",
    "from torch import Tensor\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# Device setup\n",
    "GPU_TO_USE = 7\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = f\"cuda:{GPU_TO_USE}\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# utility to clear variables out of the memory & and clearing cuda cache\n",
    "import gc\n",
    "def clear_cache():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jfJj5lw7i6mQ"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_data_path(data_folder, in_colab=COLAB):\n",
    "  if in_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    return Path(f'/content/drive/MyDrive/{data_folder}')\n",
    "  else:\n",
    "    return Path(f'./{data_folder}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pm2sgODvkSY_",
    "outputId": "009fc7d5-1a98-47ff-e78c-bca50c037ac1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = get_data_path('./data')\n",
    "datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory (sfc_deception) to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taras/.conda/envs/taras_aisc/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING:root:You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constant Setting center_unembed=False instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gemma-2-2b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.48it/s]\n",
      "WARNING:root:With reduced precision, it is advised to use `from_pretrained_no_processing` instead of `from_pretrained`.\n",
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gemma-2-2b into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HookedSAETransformer(\n",
       "  (embed): Embed()\n",
       "  (hook_embed): HookPoint()\n",
       "  (blocks): ModuleList(\n",
       "    (0-25): 26 x TransformerBlock(\n",
       "      (ln1): RMSNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln1_post): RMSNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2): RMSNormPre(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (ln2_post): RMSNorm(\n",
       "        (hook_scale): HookPoint()\n",
       "        (hook_normalized): HookPoint()\n",
       "      )\n",
       "      (attn): GroupedQueryAttention(\n",
       "        (hook_k): HookPoint()\n",
       "        (hook_q): HookPoint()\n",
       "        (hook_v): HookPoint()\n",
       "        (hook_z): HookPoint()\n",
       "        (hook_attn_scores): HookPoint()\n",
       "        (hook_pattern): HookPoint()\n",
       "        (hook_result): HookPoint()\n",
       "        (hook_rot_k): HookPoint()\n",
       "        (hook_rot_q): HookPoint()\n",
       "      )\n",
       "      (mlp): GatedMLP(\n",
       "        (hook_pre): HookPoint()\n",
       "        (hook_pre_linear): HookPoint()\n",
       "        (hook_post): HookPoint()\n",
       "      )\n",
       "      (hook_attn_in): HookPoint()\n",
       "      (hook_q_input): HookPoint()\n",
       "      (hook_k_input): HookPoint()\n",
       "      (hook_v_input): HookPoint()\n",
       "      (hook_mlp_in): HookPoint()\n",
       "      (hook_attn_out): HookPoint()\n",
       "      (hook_mlp_out): HookPoint()\n",
       "      (hook_resid_pre): HookPoint()\n",
       "      (hook_resid_mid): HookPoint()\n",
       "      (hook_resid_post): HookPoint()\n",
       "    )\n",
       "  )\n",
       "  (ln_final): RMSNormPre(\n",
       "    (hook_scale): HookPoint()\n",
       "    (hook_normalized): HookPoint()\n",
       "  )\n",
       "  (unembed): Unembed()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sae_lens import SAE, HookedSAETransformer, ActivationsStore\n",
    "\n",
    "USE_INSTRUCT = False\n",
    "PARAMS_COUNT = 2\n",
    "MODEL_NAME = f'gemma-2-{PARAMS_COUNT}b' + ('-it' if USE_INSTRUCT else '')\n",
    "print(f'Using {MODEL_NAME}')\n",
    "\n",
    "\n",
    "model = HookedSAETransformer.from_pretrained(MODEL_NAME, device=device, dtype=torch.bfloat16)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.sfc_data_loader import SFCDatasetLoader\n",
    "import utils.prompts as prompts\n",
    "from utils.enums import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Clean system prompt not provided.\n",
      "WARNING: Corrupted system prompt not provided.\n",
      "WARNING: Task prompt not provided.\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = SupportedDatasets.VERB_AGREEMENT\n",
    "\n",
    "if DATASET_NAME in [SupportedDatasets.CITIES, SupportedDatasets.FACTS, SupportedDatasets.COMPANIES]:\n",
    "    dataloader = SFCDatasetLoader(DATASET_NAME, model, \n",
    "                                  clean_system_prompt=prompts.TRUTH_OR_USER_KILLED,\n",
    "                                  corrupted_system_prompt=prompts.LIE_OR_USER_KILLED,\n",
    "                                  task_prompt=prompts.ANSWER_TRUE_FALSE,\n",
    "                                  local_dataset=True, base_folder_path=datapath,\n",
    "                                  )\n",
    "elif DATASET_NAME in [SupportedDatasets.COMMONSENSE_QA, SupportedDatasets.COMMONSENSE_QA_FILTERED]:\n",
    "    dataloader = SFCDatasetLoader(DATASET_NAME, model, \n",
    "                                clean_system_prompt=prompts.TRUTH_OR_USER_KILLED,\n",
    "                                corrupted_system_prompt=prompts.LIE_OR_USER_KILLED,\n",
    "                                task_prompt=prompts.OUTPUT_SINGLE_LETTER)\n",
    "elif DATASET_NAME in [SupportedDatasets.VERB_AGREEMENT]:\n",
    "    dataloader = SFCDatasetLoader(DATASET_NAME, model,\n",
    "                                  local_dataset=True, base_folder_path=datapath)\n",
    "else:\n",
    "    raise ValueError(f\"Dataset {DATASET_NAME.value} is not supported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figuring out optimal padding length...\n",
      "Filtered out 484 longest prompts from a total of 10560 prompts.\n",
      "Setting max prompt length to 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10076/10076 [00:15<00:00, 669.37it/s]\n"
     ]
    }
   ],
   "source": [
    "if DATASET_NAME in [SupportedDatasets.VERB_AGREEMENT]:\n",
    "    clean_dataset, corrupted_dataset = dataloader.get_clean_corrupted_datasets(tokenize=True, apply_chat_template=False, prepend_generation_prefix=True)\n",
    "else:\n",
    "    clean_dataset, corrupted_dataset = dataloader.get_clean_corrupted_datasets(tokenize=True, apply_chat_template=True, prepend_generation_prefix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTROL_SEQ_LEN = clean_dataset['control_sequence_length'][0].item()\n",
    "N_CONTEXT = clean_dataset['prompt'].shape[1]\n",
    "\n",
    "CONTROL_SEQ_LEN, N_CONTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean dataset:\n",
      "\n",
      "Prompt: <bos>The doctors that the executives like<pad>\n",
      "\n",
      "(-2, <bos>) (-1, The) (0,  doctors) (1,  that) (2,  the) (3,  executives) (4,  like) (5, <pad>) \n",
      "\n",
      "Prompt: <bos>The fathers that the driver visits<pad>\n",
      "\n",
      "(-2, <bos>) (-1, The) (0,  fathers) (1,  that) (2,  the) (3,  driver) (4,  visits) (5, <pad>) \n",
      "\n",
      "Prompt: <bos>The boys that the parents inform<pad>\n",
      "\n",
      "(-2, <bos>) (-1, The) (0,  boys) (1,  that) (2,  the) (3,  parents) (4,  inform) (5, <pad>) \n",
      "Corrupted dataset:\n",
      "\n",
      "Prompt: <bos>The doctor that the executives like<pad>\n",
      "\n",
      "(-2, <bos>) (-1, The) (0,  doctor) (1,  that) (2,  the) (3,  executives) (4,  like) (5, <pad>) \n",
      "\n",
      "Prompt: <bos>The father that the driver visits<pad>\n",
      "\n",
      "(-2, <bos>) (-1, The) (0,  father) (1,  that) (2,  the) (3,  driver) (4,  visits) (5, <pad>) \n",
      "\n",
      "Prompt: <bos>The boy that the parents inform<pad>\n",
      "\n",
      "(-2, <bos>) (-1, The) (0,  boy) (1,  that) (2,  the) (3,  parents) (4,  inform) (5, <pad>) \n"
     ]
    }
   ],
   "source": [
    "print('Clean dataset:')\n",
    "for prompt in clean_dataset['prompt'][:3]:\n",
    "  print(\"\\nPrompt:\", model.to_string(prompt), end='\\n\\n')\n",
    "\n",
    "  for i, tok in enumerate(prompt):\n",
    "    str_token = model.to_string(tok)\n",
    "    print(f\"({i-CONTROL_SEQ_LEN}, {str_token})\", end=' ')\n",
    "  print()\n",
    "\n",
    "print('Corrupted dataset:')\n",
    "for prompt in corrupted_dataset['prompt'][:3]:\n",
    "  print(\"\\nPrompt:\", model.to_string(prompt), end='\\n\\n')\n",
    "  \n",
    "  for i, tok in enumerate(prompt):\n",
    "    str_token = model.to_string(tok)\n",
    "    print(f\"({i-CONTROL_SEQ_LEN}, {str_token})\", end=' ')\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "\n",
    "# Control sequence length must be the same for all samples in both datasets\n",
    "clean_ds_control_len = clean_dataset['control_sequence_length']\n",
    "corrupted_ds_control_len = corrupted_dataset['control_sequence_length']\n",
    "\n",
    "assert torch.all(corrupted_ds_control_len == corrupted_ds_control_len[0]), \"Control sequence length is not the same for all samples in the dataset\"\n",
    "assert torch.all(clean_ds_control_len == clean_ds_control_len[0]), \"Control sequence length is not the same for all samples in the dataset\"\n",
    "assert clean_ds_control_len[0] == corrupted_ds_control_len[0], \"Control sequence length is not the same for clean and corrupted samples in the dataset\"\n",
    "assert clean_dataset['answer'].max().item() < model.cfg.d_vocab, \"Clean answers exceed vocab size\"\n",
    "assert corrupted_dataset['answer'].max().item() < model.cfg.d_vocab, \"Patched answers exceed vocab size\"\n",
    "assert (clean_dataset['answer_pos'] < N_CONTEXT).all().item(), \"Answer positions exceed logits length\"\n",
    "assert (corrupted_dataset['answer_pos'] < N_CONTEXT).all().item(), \"Answer positions exceed logits length\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dataset(start_idx=0, end_idx=-1, clean_dataset=None, corrupted_dataset=None):\n",
    "    assert clean_dataset is not None or corrupted_dataset is not None, 'At least one dataset must be provided.'\n",
    "    return_values = []\n",
    "\n",
    "    for key in ['prompt', 'answer', 'answer_pos', 'attention_mask']:\n",
    "        if clean_dataset is not None:\n",
    "            return_values.append(clean_dataset[key][start_idx:end_idx])\n",
    "        if corrupted_dataset is not None:\n",
    "            return_values.append(corrupted_dataset[key][start_idx:end_idx])\n",
    "\n",
    "    return return_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the SAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the model with SAEs...\n",
      "Device for SAEs: cuda:7\n"
     ]
    }
   ],
   "source": [
    "from classes.sfc_model import *\n",
    "\n",
    "RUN_WITH_SAES = True\n",
    "\n",
    "if RUN_WITH_SAES:\n",
    "    caching_device = device \n",
    "else:\n",
    "    caching_device = \"cuda:6\"\n",
    "\n",
    "\n",
    "print('Running the model' + (' with SAEs' if RUN_WITH_SAES else '') + '...')\n",
    "print(f'Device for SAEs: {caching_device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16K SAEs for the first 26 layers, the rest 0 layer(s) - 131k SAEs\n",
      "Number of SAEs: 78\n",
      "blocks.0.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.1.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.2.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.3.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.4.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.5.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.6.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.7.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.8.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.9.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.10.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.11.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.12.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.13.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.14.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.15.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.16.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.17.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.18.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.19.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.20.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.21.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.22.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.23.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.24.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.25.hook_resid_post SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.0.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.1.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.2.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.3.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.4.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.5.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.6.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.7.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.8.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.9.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.10.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.11.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.12.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.13.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.14.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.15.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.16.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.17.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.18.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.19.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.20.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.21.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.22.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.23.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.24.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.25.hook_mlp_out SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.0.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.1.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.2.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.3.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.4.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.5.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.6.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.7.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.8.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.9.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.10.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.11.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.12.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.13.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.14.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.15.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.16.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.17.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.18.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.19.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.20.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.21.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.22.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.23.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.24.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n",
      "blocks.25.attn.hook_z SAE(\n",
      "  (activation_fn): ReLU()\n",
      "  (hook_sae_input): HookPoint()\n",
      "  (hook_sae_acts_pre): HookPoint()\n",
      "  (hook_sae_acts_post): HookPoint()\n",
      "  (hook_sae_output): HookPoint()\n",
      "  (hook_sae_recons): HookPoint()\n",
      "  (hook_sae_error): HookPoint()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "clear_cache()\n",
    "\n",
    "sfc_model = SFC_Gemma(model, params_count=PARAMS_COUNT, control_seq_len=CONTROL_SEQ_LEN, \n",
    "                      attach_saes=RUN_WITH_SAES, caching_device=caching_device)\n",
    "sfc_model.print_saes()\n",
    "\n",
    "clear_cache()\n",
    "\n",
    "# sfc_model.model.cfg\n",
    "# , sfc_model.saes[0].cfg.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEBXjdpZ9ppj"
   },
   "source": [
    "# Getting the SFC nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading None_agg_rc_dataset_scores.pkl...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['blocks.0.attn.hook_z.hook_sae_error', 'blocks.0.attn.hook_z.hook_sae_acts_post', 'blocks.0.hook_mlp_out.hook_sae_error', 'blocks.0.hook_mlp_out.hook_sae_acts_post', 'blocks.0.hook_resid_post.hook_sae_error', 'blocks.0.hook_resid_post.hook_sae_acts_post', 'blocks.1.attn.hook_z.hook_sae_error', 'blocks.1.attn.hook_z.hook_sae_acts_post', 'blocks.1.hook_mlp_out.hook_sae_error', 'blocks.1.hook_mlp_out.hook_sae_acts_post', 'blocks.1.hook_resid_post.hook_sae_error', 'blocks.1.hook_resid_post.hook_sae_acts_post', 'blocks.2.attn.hook_z.hook_sae_error', 'blocks.2.attn.hook_z.hook_sae_acts_post', 'blocks.2.hook_mlp_out.hook_sae_error', 'blocks.2.hook_mlp_out.hook_sae_acts_post', 'blocks.2.hook_resid_post.hook_sae_error', 'blocks.2.hook_resid_post.hook_sae_acts_post', 'blocks.3.attn.hook_z.hook_sae_error', 'blocks.3.attn.hook_z.hook_sae_acts_post', 'blocks.3.hook_mlp_out.hook_sae_error', 'blocks.3.hook_mlp_out.hook_sae_acts_post', 'blocks.3.hook_resid_post.hook_sae_error', 'blocks.3.hook_resid_post.hook_sae_acts_post', 'blocks.4.attn.hook_z.hook_sae_error', 'blocks.4.attn.hook_z.hook_sae_acts_post', 'blocks.4.hook_mlp_out.hook_sae_error', 'blocks.4.hook_mlp_out.hook_sae_acts_post', 'blocks.4.hook_resid_post.hook_sae_error', 'blocks.4.hook_resid_post.hook_sae_acts_post', 'blocks.5.attn.hook_z.hook_sae_error', 'blocks.5.attn.hook_z.hook_sae_acts_post', 'blocks.5.hook_mlp_out.hook_sae_error', 'blocks.5.hook_mlp_out.hook_sae_acts_post', 'blocks.5.hook_resid_post.hook_sae_error', 'blocks.5.hook_resid_post.hook_sae_acts_post', 'blocks.6.attn.hook_z.hook_sae_error', 'blocks.6.attn.hook_z.hook_sae_acts_post', 'blocks.6.hook_mlp_out.hook_sae_error', 'blocks.6.hook_mlp_out.hook_sae_acts_post', 'blocks.6.hook_resid_post.hook_sae_error', 'blocks.6.hook_resid_post.hook_sae_acts_post', 'blocks.7.attn.hook_z.hook_sae_error', 'blocks.7.attn.hook_z.hook_sae_acts_post', 'blocks.7.hook_mlp_out.hook_sae_error', 'blocks.7.hook_mlp_out.hook_sae_acts_post', 'blocks.7.hook_resid_post.hook_sae_error', 'blocks.7.hook_resid_post.hook_sae_acts_post', 'blocks.8.attn.hook_z.hook_sae_error', 'blocks.8.attn.hook_z.hook_sae_acts_post', 'blocks.8.hook_mlp_out.hook_sae_error', 'blocks.8.hook_mlp_out.hook_sae_acts_post', 'blocks.8.hook_resid_post.hook_sae_error', 'blocks.8.hook_resid_post.hook_sae_acts_post', 'blocks.9.attn.hook_z.hook_sae_error', 'blocks.9.attn.hook_z.hook_sae_acts_post', 'blocks.9.hook_mlp_out.hook_sae_error', 'blocks.9.hook_mlp_out.hook_sae_acts_post', 'blocks.9.hook_resid_post.hook_sae_error', 'blocks.9.hook_resid_post.hook_sae_acts_post', 'blocks.10.attn.hook_z.hook_sae_error', 'blocks.10.attn.hook_z.hook_sae_acts_post', 'blocks.10.hook_mlp_out.hook_sae_error', 'blocks.10.hook_mlp_out.hook_sae_acts_post', 'blocks.10.hook_resid_post.hook_sae_error', 'blocks.10.hook_resid_post.hook_sae_acts_post', 'blocks.11.attn.hook_z.hook_sae_error', 'blocks.11.attn.hook_z.hook_sae_acts_post', 'blocks.11.hook_mlp_out.hook_sae_error', 'blocks.11.hook_mlp_out.hook_sae_acts_post', 'blocks.11.hook_resid_post.hook_sae_error', 'blocks.11.hook_resid_post.hook_sae_acts_post', 'blocks.12.attn.hook_z.hook_sae_error', 'blocks.12.attn.hook_z.hook_sae_acts_post', 'blocks.12.hook_mlp_out.hook_sae_error', 'blocks.12.hook_mlp_out.hook_sae_acts_post', 'blocks.12.hook_resid_post.hook_sae_error', 'blocks.12.hook_resid_post.hook_sae_acts_post', 'blocks.13.attn.hook_z.hook_sae_error', 'blocks.13.attn.hook_z.hook_sae_acts_post', 'blocks.13.hook_mlp_out.hook_sae_error', 'blocks.13.hook_mlp_out.hook_sae_acts_post', 'blocks.13.hook_resid_post.hook_sae_error', 'blocks.13.hook_resid_post.hook_sae_acts_post', 'blocks.14.attn.hook_z.hook_sae_error', 'blocks.14.attn.hook_z.hook_sae_acts_post', 'blocks.14.hook_mlp_out.hook_sae_error', 'blocks.14.hook_mlp_out.hook_sae_acts_post', 'blocks.14.hook_resid_post.hook_sae_error', 'blocks.14.hook_resid_post.hook_sae_acts_post', 'blocks.15.attn.hook_z.hook_sae_error', 'blocks.15.attn.hook_z.hook_sae_acts_post', 'blocks.15.hook_mlp_out.hook_sae_error', 'blocks.15.hook_mlp_out.hook_sae_acts_post', 'blocks.15.hook_resid_post.hook_sae_error', 'blocks.15.hook_resid_post.hook_sae_acts_post', 'blocks.16.attn.hook_z.hook_sae_error', 'blocks.16.attn.hook_z.hook_sae_acts_post', 'blocks.16.hook_mlp_out.hook_sae_error', 'blocks.16.hook_mlp_out.hook_sae_acts_post', 'blocks.16.hook_resid_post.hook_sae_error', 'blocks.16.hook_resid_post.hook_sae_acts_post', 'blocks.17.attn.hook_z.hook_sae_error', 'blocks.17.attn.hook_z.hook_sae_acts_post', 'blocks.17.hook_mlp_out.hook_sae_error', 'blocks.17.hook_mlp_out.hook_sae_acts_post', 'blocks.17.hook_resid_post.hook_sae_error', 'blocks.17.hook_resid_post.hook_sae_acts_post', 'blocks.18.attn.hook_z.hook_sae_error', 'blocks.18.attn.hook_z.hook_sae_acts_post', 'blocks.18.hook_mlp_out.hook_sae_error', 'blocks.18.hook_mlp_out.hook_sae_acts_post', 'blocks.18.hook_resid_post.hook_sae_error', 'blocks.18.hook_resid_post.hook_sae_acts_post', 'blocks.19.attn.hook_z.hook_sae_error', 'blocks.19.attn.hook_z.hook_sae_acts_post', 'blocks.19.hook_mlp_out.hook_sae_error', 'blocks.19.hook_mlp_out.hook_sae_acts_post', 'blocks.19.hook_resid_post.hook_sae_error', 'blocks.19.hook_resid_post.hook_sae_acts_post', 'blocks.20.attn.hook_z.hook_sae_error', 'blocks.20.attn.hook_z.hook_sae_acts_post', 'blocks.20.hook_mlp_out.hook_sae_error', 'blocks.20.hook_mlp_out.hook_sae_acts_post', 'blocks.20.hook_resid_post.hook_sae_error', 'blocks.20.hook_resid_post.hook_sae_acts_post', 'blocks.21.attn.hook_z.hook_sae_error', 'blocks.21.attn.hook_z.hook_sae_acts_post', 'blocks.21.hook_mlp_out.hook_sae_error', 'blocks.21.hook_mlp_out.hook_sae_acts_post', 'blocks.21.hook_resid_post.hook_sae_error', 'blocks.21.hook_resid_post.hook_sae_acts_post', 'blocks.22.attn.hook_z.hook_sae_error', 'blocks.22.attn.hook_z.hook_sae_acts_post', 'blocks.22.hook_mlp_out.hook_sae_error', 'blocks.22.hook_mlp_out.hook_sae_acts_post', 'blocks.22.hook_resid_post.hook_sae_error', 'blocks.22.hook_resid_post.hook_sae_acts_post', 'blocks.23.attn.hook_z.hook_sae_error', 'blocks.23.attn.hook_z.hook_sae_acts_post', 'blocks.23.hook_mlp_out.hook_sae_error', 'blocks.23.hook_mlp_out.hook_sae_acts_post', 'blocks.23.hook_resid_post.hook_sae_error', 'blocks.23.hook_resid_post.hook_sae_acts_post', 'blocks.24.attn.hook_z.hook_sae_error', 'blocks.24.attn.hook_z.hook_sae_acts_post', 'blocks.24.hook_mlp_out.hook_sae_error', 'blocks.24.hook_mlp_out.hook_sae_acts_post', 'blocks.24.hook_resid_post.hook_sae_error', 'blocks.24.hook_resid_post.hook_sae_acts_post', 'blocks.25.attn.hook_z.hook_sae_error', 'blocks.25.attn.hook_z.hook_sae_acts_post', 'blocks.25.hook_mlp_out.hook_sae_error', 'blocks.25.hook_mlp_out.hook_sae_acts_post', 'blocks.25.hook_resid_post.hook_sae_error', 'blocks.25.hook_resid_post.hook_sae_acts_post'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def load_dict(nodes_prefix='rc_dataset', aggregated_tokens=True):\n",
    "    aggregation_type = 'All_tokens' if aggregated_tokens else 'None'\n",
    "\n",
    "    if nodes_prefix:\n",
    "        filename = f'{aggregation_type}_agg_{nodes_prefix}_scores.pkl'\n",
    "    else:\n",
    "        filename = f'{aggregation_type}_agg_scores.pkl'\n",
    "\n",
    "    print(f'Loading {filename}...')\n",
    "    filename = datapath / filename\n",
    "\n",
    "    with open(filename, 'rb') as f:\n",
    "        data_dict = pickle.load(f)\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "nodes_dict = load_dict(aggregated_tokens=False)\n",
    "nodes_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 16384]), torch.Size([8]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_dict['blocks.0.attn.hook_z.hook_sae_acts_post'].shape, nodes_dict['blocks.0.attn.hook_z.hook_sae_error'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['blocks.5.hook_resid_post.hook_sae_acts_post', 'blocks.14.hook_resid_post.hook_sae_acts_post', 'blocks.15.hook_resid_post.hook_sae_error', 'blocks.15.hook_resid_post.hook_sae_acts_post', 'blocks.16.hook_resid_post.hook_sae_acts_post', 'blocks.17.hook_mlp_out.hook_sae_acts_post', 'blocks.17.hook_resid_post.hook_sae_error', 'blocks.18.hook_resid_post.hook_sae_error', 'blocks.18.hook_resid_post.hook_sae_acts_post', 'blocks.19.attn.hook_z.hook_sae_acts_post', 'blocks.19.hook_mlp_out.hook_sae_acts_post', 'blocks.19.hook_resid_post.hook_sae_error', 'blocks.19.hook_resid_post.hook_sae_acts_post', 'blocks.20.hook_resid_post.hook_sae_acts_post', 'blocks.21.hook_mlp_out.hook_sae_acts_post', 'blocks.21.hook_resid_post.hook_sae_acts_post', 'blocks.22.hook_mlp_out.hook_sae_acts_post', 'blocks.22.hook_resid_post.hook_sae_acts_post', 'blocks.23.hook_resid_post.hook_sae_acts_post', 'blocks.24.hook_resid_post.hook_sae_acts_post', 'blocks.25.hook_resid_post.hook_sae_acts_post']),\n",
       " dict_keys(['blocks.5.hook_resid_post.hook_sae_acts_post', 'blocks.14.hook_resid_post.hook_sae_acts_post', 'blocks.15.hook_resid_post.hook_sae_error', 'blocks.15.hook_resid_post.hook_sae_acts_post', 'blocks.16.hook_resid_post.hook_sae_acts_post', 'blocks.17.hook_mlp_out.hook_sae_acts_post', 'blocks.17.hook_resid_post.hook_sae_error', 'blocks.18.hook_resid_post.hook_sae_error', 'blocks.18.hook_resid_post.hook_sae_acts_post', 'blocks.19.attn.hook_z.hook_sae_acts_post', 'blocks.19.hook_mlp_out.hook_sae_acts_post', 'blocks.19.hook_resid_post.hook_sae_error', 'blocks.19.hook_resid_post.hook_sae_acts_post', 'blocks.20.hook_resid_post.hook_sae_acts_post', 'blocks.21.hook_mlp_out.hook_sae_acts_post', 'blocks.21.hook_resid_post.hook_sae_acts_post', 'blocks.22.hook_mlp_out.hook_sae_acts_post', 'blocks.22.hook_resid_post.hook_sae_acts_post', 'blocks.23.hook_resid_post.hook_sae_acts_post', 'blocks.24.hook_resid_post.hook_sae_acts_post', 'blocks.25.hook_resid_post.hook_sae_acts_post']))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_sae_importance(data_dict, threshold):\n",
    "    \"\"\"\n",
    "    Filters the input dictionary, keeping only the entries where at least one value exceeds the threshold.\n",
    "    Also returns binary masks indicating which elements exceed the threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - data_dict (dict): A dictionary where keys are activation names and values are torch tensors.\n",
    "    - threshold (float): The threshold for filtering.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A filtered dictionary containing only the keys where torch.any(tensor > threshold) is True.\n",
    "    - dict: A dictionary of binary masks indicating which elements exceed the threshold.\n",
    "    \"\"\"\n",
    "    filtered_dict = {}\n",
    "    masks_dict = {}\n",
    "    \n",
    "    for key, tensor in data_dict.items():\n",
    "        mask = tensor > threshold\n",
    "        if torch.any(mask):\n",
    "            filtered_dict[key] = tensor\n",
    "            masks_dict[key] = mask\n",
    "    \n",
    "    return filtered_dict, masks_dict\n",
    "\n",
    "\n",
    "filtered_nodes, nodes_mask = filter_sae_importance(nodes_dict, 0.005)\n",
    "filtered_nodes.keys(), nodes_mask.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_name_to_hook_name(act_name, return_node_type=False):\n",
    "    \"\"\"\n",
    "    Extracts the hook name from an SAE activation name.\n",
    "    For example:\n",
    "        'blocks.0.attn.hook_z.hook_sae_acts_post' -> 'hook_z'\n",
    "        'blocks.19.hook_mlp_out.hook_sae_error' -> 'hook_mlp_out'\n",
    "        'blocks.18.hook_resid_post.hook_sae_acts_post' -> 'hook_resid_post'\n",
    "    \"\"\"\n",
    "    parts = act_name.split('.')\n",
    "    if parts[-1] not in ['hook_sae_acts_post', 'hook_sae_error']:\n",
    "        raise ValueError(\"Activation name is not an SAE activation name.\")\n",
    "    if not parts[-2].startswith('hook_'):\n",
    "        raise ValueError(\"Activation name does not follow the expected format.\")\n",
    "\n",
    "    return parts[-2] if not return_node_type else (parts[-2], parts[-1])\n",
    "\n",
    "def act_name_to_layer_number(act_name):\n",
    "    # Split the input string by periods\n",
    "    parts = act_name.split('.')\n",
    "    \n",
    "    # Validate that the string has the correct format\n",
    "    if len(parts) < 3 or parts[0] != 'blocks':\n",
    "        raise ValueError(f\"Input string must start with 'blocks.<index>.'. Got: {act_name}\")\n",
    "    \n",
    "    # Extract and return the block number as an integer\n",
    "    return int(parts[1])\n",
    "\n",
    "\n",
    "def get_adjacent_nodes(filtered_nodes, nodes_mask):\n",
    "    \"\"\"\n",
    "    Returns a dictionary where keys are SFC parent nodes and values are their children nodes, i.e. the nodes that are directly upstream w.r.t.\n",
    "    the parent nodes. More precisely, the format is:\n",
    "    {\n",
    "        'parent_node_name': [\n",
    "            ('child_node_1', None),\n",
    "            ('child_node_2', None),\n",
    "            ...\n",
    "        ],\n",
    "        ...\n",
    "    }\n",
    "    where None value is to be filled with the gradient of the child node w.r.t. the parent node.\n",
    "    Additionally, returns the metadata of the adjacent nodes.\n",
    "    \"\"\"\n",
    "    def is_node_adjacent(parent_name, parent_layer, child_name, child_layer):\n",
    "        \"\"\"\n",
    "        Checks if two hooks can be adjacent based on the hook name.\n",
    "        \"\"\"\n",
    "        if parent_name == 'hook_resid_post':\n",
    "            if child_name == 'hook_resid_post':\n",
    "                return parent_layer - 1 == child_layer\n",
    "            else:\n",
    "                return parent_layer == child_layer\n",
    "\n",
    "        if parent_name == 'hook_mlp_out':\n",
    "            if child_name == 'hook_resid_post':\n",
    "                return parent_layer - 1 == child_layer\n",
    "            elif child_name == 'hook_z':\n",
    "                return parent_layer == child_layer\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "        if parent_name == 'hook_z':\n",
    "            return child_name == 'hook_resid_post' and parent_layer - 1 == child_layer\n",
    "        \n",
    "        raise ValueError(f\"Hook name is not recognized: {parent_name}\")\n",
    "    \n",
    "    \n",
    "    adjacent_nodes = {}\n",
    "    adjacent_nodes_metadata = {}\n",
    "\n",
    "    for parent_act in filtered_nodes.keys():\n",
    "        parent_hook_name, parent_node_type = act_name_to_hook_name(parent_act, return_node_type=True)\n",
    "        parent_layer_num = act_name_to_layer_number(parent_act)\n",
    "\n",
    "        for child_act in filtered_nodes.keys():\n",
    "            child_hook_name, child_node_type = act_name_to_hook_name(child_act, return_node_type=True)\n",
    "            child_layer_num = act_name_to_layer_number(child_act)\n",
    "\n",
    "            if is_node_adjacent(parent_hook_name, parent_layer_num, child_hook_name, child_layer_num):\n",
    "                if parent_act not in adjacent_nodes:\n",
    "                    adjacent_nodes[parent_act] = []\n",
    "                    adjacent_nodes_metadata[parent_act] = []\n",
    "\n",
    "                adjacent_nodes[parent_act].append((child_act, None)) # initialize the gradient of the child node to None\n",
    "                adjacent_nodes_metadata[parent_act].append({\n",
    "                    'child_name': child_act,\n",
    "                    'parent_hook': parent_hook_name,\n",
    "                    'child_hook': child_hook_name,\n",
    "                    'parent_layer': parent_layer_num,\n",
    "                    'child_layer': child_layer_num,\n",
    "                    'is_parent_error': parent_node_type == 'hook_sae_error',\n",
    "                    'is_child_error': child_node_type == 'hook_sae_error',\n",
    "                    'parent_threshold_mask': nodes_mask[parent_act],\n",
    "                    'child_threshold_mask': nodes_mask[child_act],\n",
    "                })\n",
    "            \n",
    "    return adjacent_nodes, adjacent_nodes_metadata\n",
    "\n",
    "def print_nodes_metadata(nodes_metadata):\n",
    "    for parent_act, metadata_list in nodes_metadata.items():\n",
    "        print(f\"\\nParent activation: {parent_act}\")\n",
    "        print(f\"  Parent hook: {metadata_list[0]['parent_hook']}\")\n",
    "        print(f\"  Parent layer: {metadata_list[0]['parent_layer']}\")\n",
    "        print(f\"  Is parent error: {metadata_list[0]['is_parent_error']}\")\n",
    "        print(f\"  Parent threshold mask shape: {metadata_list[0]['parent_threshold_mask'].shape}\")\n",
    "        print('-'*47)\n",
    "\n",
    "        for metadata in metadata_list:\n",
    "            print(f\"  Child activation: {metadata['child_name']}\")\n",
    "            print(f\"  Child hook: {metadata['child_hook']}\")\n",
    "            print(f\"  Child layer: {metadata['child_layer']}\")\n",
    "            print(f\"  Is child error: {metadata['is_child_error']}\")\n",
    "            print(f\"  Child threshold mask shape: {metadata['child_threshold_mask'].shape}\")\n",
    "            print('-'*47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['blocks.5.hook_resid_post.hook_sae_acts_post', 'blocks.14.hook_resid_post.hook_sae_acts_post', 'blocks.15.hook_resid_post.hook_sae_error', 'blocks.15.hook_resid_post.hook_sae_acts_post', 'blocks.16.hook_resid_post.hook_sae_acts_post', 'blocks.17.hook_mlp_out.hook_sae_acts_post', 'blocks.17.hook_resid_post.hook_sae_error', 'blocks.18.hook_resid_post.hook_sae_error', 'blocks.18.hook_resid_post.hook_sae_acts_post', 'blocks.19.attn.hook_z.hook_sae_acts_post', 'blocks.19.hook_mlp_out.hook_sae_acts_post', 'blocks.19.hook_resid_post.hook_sae_error', 'blocks.19.hook_resid_post.hook_sae_acts_post', 'blocks.20.hook_resid_post.hook_sae_acts_post', 'blocks.21.hook_mlp_out.hook_sae_acts_post', 'blocks.21.hook_resid_post.hook_sae_acts_post', 'blocks.22.hook_mlp_out.hook_sae_acts_post', 'blocks.22.hook_resid_post.hook_sae_acts_post', 'blocks.23.hook_resid_post.hook_sae_acts_post', 'blocks.24.hook_resid_post.hook_sae_acts_post', 'blocks.25.hook_resid_post.hook_sae_acts_post'])\n"
     ]
    }
   ],
   "source": [
    "print(filtered_nodes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 21, 19)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacent_nodes, adjacent_nodes_metadata = get_adjacent_nodes(filtered_nodes, nodes_mask)\n",
    "len(adjacent_nodes.keys()), len(filtered_nodes.keys()), len(adjacent_nodes_metadata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0086, 0.0041, 0.0023, 0.0019, 0.0006, 0.0003, 0.0003, 0.0003, 0.0003,\n",
       "         0.0002], device='cuda:6', dtype=torch.bfloat16),\n",
       " tensor([ 3716, 10073, 10884, 10500,  6714, 15690,  5795, 10943, 13379,  8022],\n",
       "        device='cuda:6'))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_name = 'blocks.19.attn.hook_z.hook_sae_acts_post'\n",
    "d = filtered_nodes[d_name]\n",
    "\n",
    "top_d, top_d_id = d.topk(10, dim=-1)\n",
    "top_d[6], top_d_id[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0129, 0.0017, 0.0009, 0.0006, 0.0005, 0.0005, 0.0004, 0.0004, 0.0004,\n",
       "         0.0004], device='cuda:6', dtype=torch.bfloat16),\n",
       " tensor([10665,  4442, 11484,  9777,  9525,  1271,  1495,  2343, 11381, 15387],\n",
       "        device='cuda:6'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_name = 'blocks.18.hook_resid_post.hook_sae_acts_post'\n",
    "u = filtered_nodes[u_name]\n",
    "\n",
    "top_u, top_u_id = u.topk(10, dim=-1)\n",
    "top_u[6], top_u_id[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_feature = 3716\n",
    "u_feature = 10665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hook_z', 19, 'hook_resid_post', 18)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_hook_name = act_name_to_hook_name(u_name)\n",
    "d_hook_name = act_name_to_hook_name(d_name)\n",
    "\n",
    "d_layer = act_name_to_layer_number(d_name)\n",
    "u_layer = act_name_to_layer_number(u_name)\n",
    "\n",
    "d_hook_name, d_layer, u_hook_name, u_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studying the toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_prompts, corrupted_prompts, clean_answers, corrupted_answers, clean_answers_pos, corrupted_answers_pos, \\\n",
    "    clean_attn_mask, corrupted_attn_mask = sample_dataset(0, 1, clean_dataset=clean_dataset, corrupted_dataset=corrupted_dataset)\n",
    "\n",
    "clean_prompts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting SAE hooks...\n"
     ]
    }
   ],
   "source": [
    "clear_cache()\n",
    "sfc_model.model.reset_hooks()\n",
    "if sfc_model.are_saes_attached():\n",
    "    print('Resetting SAE hooks...')\n",
    "    sfc_model._reset_sae_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the forward cache for the selected nodes\n",
    "fwd_cache = {}\n",
    "fwd_cache_filter = lambda name: name in filtered_nodes.keys()\n",
    "\n",
    "def forward_cache_hook(act, hook):\n",
    "    fwd_cache[hook.name] = act\n",
    "\n",
    "model.add_hook(fwd_cache_filter, forward_cache_hook, \"fwd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.18.hook_resid_post.hook_sae_acts_post'"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attaching the backward hook to compute edges only for the selected nodes\n",
    "bwd_cache = {}\n",
    "bwd_cache_filter = lambda name: 'resid' in name or 'hook_z' in name or 'hook_mlp_out' in name\n",
    "\n",
    "def backward_cache_hook(grad, hook):\n",
    "    print(hook.name)\n",
    "\n",
    "    # If the node is at the source node SAE site, store the gradients and stop the propagation\n",
    "    if u_name == hook.name:\n",
    "        print(f'Storing...')\n",
    "\n",
    "        bwd_cache[hook.name] = grad\n",
    "\n",
    "        raise StopIteration()\n",
    "\n",
    "    # If the node is at the target node SAE site, let it flow to its destination (SAE latent/error tern)\n",
    "    if u_hook_name in hook.name and hook.layer() == u_layer:\n",
    "        print(f'Letting the gradients flow...')\n",
    "        return (grad,)\n",
    "\n",
    "    # If the node is the starting node, let the gradients flow\n",
    "    if d_hook_name in hook.name and hook.layer() == d_layer:\n",
    "        bwd_cache[hook.name] = grad\n",
    "        \n",
    "        print(f'Letting the gradients flow...')\n",
    "        return (grad,)\n",
    "    \n",
    "    if 'resid' in hook.name:\n",
    "        bwd_cache[hook.name] = grad\n",
    "        return (grad,)\n",
    "\n",
    "    print(f'Stopping the gradients...')\n",
    "    # If the node is intermediate, stop the propagation of gradients\n",
    "    return (None,)\n",
    "\n",
    "model.add_hook(bwd_cache_filter, backward_cache_hook, \"bwd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 16384]), True)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_act = fwd_cache[d_name]\n",
    "d_act.shape, d_act.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 16384])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "d_act_grad = F.one_hot(torch.tensor([d_feature]), num_classes=d_act.shape[-1]).squeeze().to(device)\n",
    "d_act_grad = einops.repeat(d_act_grad, 'd -> batch pos d', batch=d_act.shape[0], pos=d_act.shape[1])\n",
    "\n",
    "d_act_grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.19.attn.hook_z.hook_sae_acts_pre\n",
      "Letting the gradients flow...\n",
      "blocks.19.attn.hook_z.hook_sae_input\n",
      "Letting the gradients flow...\n",
      "blocks.19.hook_resid_pre\n",
      "blocks.18.hook_resid_post.hook_sae_output\n",
      "Letting the gradients flow...\n",
      "blocks.18.hook_resid_post.hook_sae_recons\n",
      "Letting the gradients flow...\n",
      "blocks.18.hook_resid_post.hook_sae_acts_post\n",
      "Storing...\n",
      "Gradient backpropagation stopped at blocks.18.hook_resid_post.hook_sae_acts_post\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.1742e-05,  6.1512e-05, -5.4169e-04,  ..., -1.0443e-04,\n",
       "           -5.1260e-05,  7.0572e-04],\n",
       "          [-7.5698e-06, -3.4094e-05, -2.9373e-04,  ..., -5.0735e-04,\n",
       "           -1.3065e-04,  8.0585e-05],\n",
       "          [ 1.9646e-04,  1.1635e-04,  9.9182e-04,  ...,  1.6403e-03,\n",
       "            7.2479e-04,  1.5717e-03],\n",
       "          ...,\n",
       "          [ 2.0623e-05, -1.4267e-03, -2.8992e-04,  ...,  1.9646e-04,\n",
       "            4.7302e-04,  4.1580e-04],\n",
       "          [-2.1210e-03, -2.9755e-03,  5.2214e-05,  ..., -1.9836e-03,\n",
       "            2.7847e-04,  1.0529e-03],\n",
       "          [-4.6921e-04, -1.6632e-03, -4.1008e-04,  ..., -1.7395e-03,\n",
       "            6.8283e-04, -1.3123e-03]]], device='cuda:7', dtype=torch.bfloat16),\n",
       " dict_keys(['blocks.19.attn.hook_z.hook_sae_acts_pre', 'blocks.19.attn.hook_z.hook_sae_input', 'blocks.19.hook_resid_pre', 'blocks.18.hook_resid_post.hook_sae_acts_post']))"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    d_act.backward(d_act_grad)\n",
    "except StopIteration:\n",
    "    print(f'Gradient backpropagation stopped at {u_name}')\n",
    "\n",
    "bwd_cache[u_name], bwd_cache.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0049, device='cuda:7', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_u_grad = bwd_cache[u_name][0, 6, u_feature]\n",
    "d_u_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.0228, 0.0170, 0.0140, 0.0121, 0.0118, 0.0116, 0.0115, 0.0113, 0.0113,\n",
       "        0.0113, 0.0112, 0.0109, 0.0107, 0.0106, 0.0105, 0.0103, 0.0100, 0.0100,\n",
       "        0.0099, 0.0098, 0.0097, 0.0096, 0.0096, 0.0095, 0.0094, 0.0093, 0.0093,\n",
       "        0.0090, 0.0090, 0.0087, 0.0087, 0.0086, 0.0086, 0.0084, 0.0084, 0.0083,\n",
       "        0.0083, 0.0083, 0.0082, 0.0082, 0.0081, 0.0080, 0.0079, 0.0079, 0.0079,\n",
       "        0.0079, 0.0079, 0.0078, 0.0077, 0.0077], device='cuda:7',\n",
       "       dtype=torch.bfloat16),\n",
       "indices=tensor([ 3085,  6305,  2860, 15786,  4239, 14539,  5696,  9579, 10318, 13789,\n",
       "        14461,  7016,  5443,  4294,  3901,  5798, 11673, 13851, 11250, 12063,\n",
       "         2862,  3140,  8197, 12368,  4471,   442,  4358, 11832,  2865,  4751,\n",
       "         6991,  6543, 16017, 11089,  9645,   401,  8353, 13807,  4968,  8969,\n",
       "        13532, 11087,   901, 10986,  3242,  8251, 11032, 13041, 11831, 11498],\n",
       "       device='cuda:7'))"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwd_cache[u_name][0, 6, :].topk(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.18.hook_resid_post.hook_sae_acts_post'"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.0091, 0.0074, 0.0071, 0.0069, 0.0065, 0.0064, 0.0063, 0.0062, 0.0060,\n",
       "        0.0058, 0.0057, 0.0055, 0.0054, 0.0054, 0.0053, 0.0053, 0.0052, 0.0052,\n",
       "        0.0050, 0.0049, 0.0048, 0.0048, 0.0048, 0.0046, 0.0046, 0.0046, 0.0045,\n",
       "        0.0044, 0.0044, 0.0044, 0.0044, 0.0043, 0.0043, 0.0043, 0.0043, 0.0042,\n",
       "        0.0042, 0.0042, 0.0042, 0.0041, 0.0041, 0.0041, 0.0041, 0.0041, 0.0040,\n",
       "        0.0040, 0.0040, 0.0040, 0.0040, 0.0040], device='cuda:7',\n",
       "       dtype=torch.bfloat16),\n",
       "indices=tensor([ 4621, 10927,  5747,  3369,  1027, 14824,  9671, 10665,  6790,  1882,\n",
       "         8104,  8129,  2502,  7379,   541, 12123, 14017, 14774,  3751, 11626,\n",
       "         8554,  1708, 12256,  8437,  5322, 11016, 11543,  1885, 12781,  7679,\n",
       "         9603, 13836, 15108, 12841,  3358,  1506,  2086,  2650,  5078,   226,\n",
       "         1524,  4377,  4211,  9294,  6004,  1546,  6217, 14754,   819, 11225],\n",
       "       device='cuda:7'))"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwd_cache[u_name][0, 2, :].topk(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005, device='cuda:7', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwd_cache[u_name][0, 2, 15377]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.18.hook_resid_post.hook_sae_acts_post'"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([4.5166e-03, 4.2419e-03, 1.0910e-03, 1.0529e-03, 2.1553e-04, 1.6689e-04,\n",
       "        1.5545e-04, 1.1110e-04, 1.0443e-04, 9.3937e-05], device='cuda:6',\n",
       "       dtype=torch.bfloat16),\n",
       "indices=tensor([10665,  1506, 15377,  1271,  4973,  1286, 15152,  4856,  5676,  2856],\n",
       "       device='cuda:6'))"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_nodes[u_name][2, :].topk(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.0086, 0.0041, 0.0023, 0.0019, 0.0006, 0.0003, 0.0003, 0.0003, 0.0003,\n",
       "        0.0002], device='cuda:6', dtype=torch.bfloat16),\n",
       "indices=tensor([ 3716, 10073, 10884, 10500,  6714, 15690,  5795, 10943, 13379,  8022],\n",
       "       device='cuda:6'))"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_nodes[d_name][6, :].topk(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:7')"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resid_post_grad = bwd_cache['blocks.19.hook_resid_post.hook_sae_input'][0, 6, :]\n",
    "resid_mid_grad = bwd_cache['blocks.19.hook_resid_mid'][0, 6, :]\n",
    "resid_pre_grad = bwd_cache['blocks.19.hook_resid_pre'][0, 6, :]\n",
    "\n",
    "# Check if the gradients are the same\n",
    "# torch.all(resid_post_grad == resid_mid_grad) \n",
    "torch.all(resid_mid_grad == resid_pre_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['blocks.19.hook_resid_post.hook_sae_acts_pre', 'blocks.19.hook_resid_post.hook_sae_input', 'blocks.19.hook_resid_mid', 'blocks.19.attn.hook_z.hook_sae_acts_post'])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwd_cache.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling edge calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parent activation: blocks.15.hook_resid_post.hook_sae_error\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 15\n",
      "  Is parent error: True\n",
      "  Parent threshold mask shape: torch.Size([8])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.14.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 14\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.15.hook_resid_post.hook_sae_acts_post\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 15\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.14.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 14\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.16.hook_resid_post.hook_sae_acts_post\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 16\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.15.hook_resid_post.hook_sae_error\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 15\n",
      "  Is child error: True\n",
      "  Child threshold mask shape: torch.Size([8])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.15.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 15\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.17.hook_mlp_out.hook_sae_acts_post\n",
      "  Parent hook: hook_mlp_out\n",
      "  Parent layer: 17\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.16.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 16\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.17.hook_resid_post.hook_sae_error\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 17\n",
      "  Is parent error: True\n",
      "  Parent threshold mask shape: torch.Size([8])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.16.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 16\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.17.hook_mlp_out.hook_sae_acts_post\n",
      "  Child hook: hook_mlp_out\n",
      "  Child layer: 17\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.18.hook_resid_post.hook_sae_error\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 18\n",
      "  Is parent error: True\n",
      "  Parent threshold mask shape: torch.Size([8])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.17.hook_resid_post.hook_sae_error\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 17\n",
      "  Is child error: True\n",
      "  Child threshold mask shape: torch.Size([8])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.18.hook_resid_post.hook_sae_acts_post\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 18\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.17.hook_resid_post.hook_sae_error\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 17\n",
      "  Is child error: True\n",
      "  Child threshold mask shape: torch.Size([8])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.19.attn.hook_z.hook_sae_acts_post\n",
      "  Parent hook: hook_z\n",
      "  Parent layer: 19\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.18.hook_resid_post.hook_sae_error\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 18\n",
      "  Is child error: True\n",
      "  Child threshold mask shape: torch.Size([8])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.18.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 18\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.19.hook_mlp_out.hook_sae_acts_post\n",
      "  Parent hook: hook_mlp_out\n",
      "  Parent layer: 19\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.18.hook_resid_post.hook_sae_error\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 18\n",
      "  Is child error: True\n",
      "  Child threshold mask shape: torch.Size([8])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.18.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 18\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.19.attn.hook_z.hook_sae_acts_post\n",
      "  Child hook: hook_z\n",
      "  Child layer: 19\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.19.hook_resid_post.hook_sae_error\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 19\n",
      "  Is parent error: True\n",
      "  Parent threshold mask shape: torch.Size([8])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.18.hook_resid_post.hook_sae_error\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 18\n",
      "  Is child error: True\n",
      "  Child threshold mask shape: torch.Size([8])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.18.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 18\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.19.attn.hook_z.hook_sae_acts_post\n",
      "  Child hook: hook_z\n",
      "  Child layer: 19\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.19.hook_mlp_out.hook_sae_acts_post\n",
      "  Child hook: hook_mlp_out\n",
      "  Child layer: 19\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.19.hook_resid_post.hook_sae_acts_post\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 19\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.18.hook_resid_post.hook_sae_error\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 18\n",
      "  Is child error: True\n",
      "  Child threshold mask shape: torch.Size([8])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.18.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 18\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.19.attn.hook_z.hook_sae_acts_post\n",
      "  Child hook: hook_z\n",
      "  Child layer: 19\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.19.hook_mlp_out.hook_sae_acts_post\n",
      "  Child hook: hook_mlp_out\n",
      "  Child layer: 19\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.20.hook_resid_post.hook_sae_acts_post\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 20\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.19.hook_resid_post.hook_sae_error\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 19\n",
      "  Is child error: True\n",
      "  Child threshold mask shape: torch.Size([8])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.19.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 19\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.21.hook_mlp_out.hook_sae_acts_post\n",
      "  Parent hook: hook_mlp_out\n",
      "  Parent layer: 21\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.20.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 20\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.21.hook_resid_post.hook_sae_acts_post\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 21\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.20.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 20\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.21.hook_mlp_out.hook_sae_acts_post\n",
      "  Child hook: hook_mlp_out\n",
      "  Child layer: 21\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.22.hook_mlp_out.hook_sae_acts_post\n",
      "  Parent hook: hook_mlp_out\n",
      "  Parent layer: 22\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.21.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 21\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.22.hook_resid_post.hook_sae_acts_post\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 22\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.21.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 21\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.22.hook_mlp_out.hook_sae_acts_post\n",
      "  Child hook: hook_mlp_out\n",
      "  Child layer: 22\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.23.hook_resid_post.hook_sae_acts_post\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 23\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.22.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 22\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.24.hook_resid_post.hook_sae_acts_post\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 24\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.23.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 23\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "\n",
      "Parent activation: blocks.25.hook_resid_post.hook_sae_acts_post\n",
      "  Parent hook: hook_resid_post\n",
      "  Parent layer: 25\n",
      "  Is parent error: False\n",
      "  Parent threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n",
      "  Child activation: blocks.24.hook_resid_post.hook_sae_acts_post\n",
      "  Child hook: hook_resid_post\n",
      "  Child layer: 24\n",
      "  Is child error: False\n",
      "  Child threshold mask shape: torch.Size([8, 16384])\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_nodes_metadata(adjacent_nodes_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detached 57 SAEs from the model.\n",
      "Discarded the remaining SAEs from memory.\n",
      "Resetting SAE hooks...\n"
     ]
    }
   ],
   "source": [
    "clean_prompts, corrupted_prompts, clean_answers, corrupted_answers, clean_answers_pos, corrupted_answers_pos, \\\n",
    "    clean_attn_mask, corrupted_attn_mask = sample_dataset(0, 1, clean_dataset=clean_dataset, corrupted_dataset=corrupted_dataset)\n",
    "\n",
    "clear_cache()\n",
    "\n",
    "sfc_model.detach_saes_except_few(filtered_nodes.keys())\n",
    "sfc_model.model.reset_hooks()\n",
    "\n",
    "if sfc_model.are_saes_attached():\n",
    "    print('Resetting SAE hooks...')\n",
    "    sfc_model._reset_sae_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Storing the forward cache for all the filtered nodes\n",
    "fwd_cache = {}\n",
    "fwd_cache_filter = lambda name: name in filtered_nodes.keys()\n",
    "\n",
    "def forward_cache_hook(act, hook):\n",
    "    fwd_cache[hook.name] = act\n",
    "\n",
    "model.add_hook(fwd_cache_filter, forward_cache_hook, \"fwd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Storing the backward cache for the parent nodes\n",
    "bwd_cache = {}\n",
    "bwd_cache_filter = lambda name: name in adjacent_nodes.keys() or 'hook_sae_output' in name or 'hook_sae_input' in name\n",
    "\n",
    "temp_cache = {}\n",
    "\n",
    "def backward_cache_hook(gradient, hook):\n",
    "    if 'hook_sae_output' in hook.name:\n",
    "        hook_sae_error_name = hook.name.replace('hook_sae_output', 'hook_sae_error')\n",
    "        if hook_sae_error_name in adjacent_nodes.keys():\n",
    "            bwd_cache[hook_sae_error_name] = gradient.detach()\n",
    "\n",
    "        # We're storing the gradients for the SAE output activations to copy them to the SAE input activations gradients\n",
    "        if not 'hook_z' in hook.name:\n",
    "            temp_cache[hook.name] = gradient.detach()\n",
    "        else: # In the case of attention hook_z hooks, reshape them to match the SAE input shape, which doesn't include n_heads\n",
    "            hook_z_grad = einops.rearrange(gradient.detach(),\n",
    "                                        'batch pos n_head d_head -> batch pos (n_head d_head)')\n",
    "            temp_cache[hook.name] = hook_z_grad\n",
    "    elif 'hook_sae_input' in hook.name:\n",
    "        # We're copying the gradients from the SAE output activations to the SAE input activations gradients\n",
    "        sae_output_grad_name = hook.name.replace('hook_sae_input', 'hook_sae_output')\n",
    "\n",
    "        gradient = temp_cache[sae_output_grad_name]\n",
    "\n",
    "        # Pass-through: use the downstream gradients\n",
    "        return (gradient,)\n",
    "    elif hook.name in adjacent_nodes.keys():\n",
    "        # Default case: just store the gradients\n",
    "        bwd_cache[hook.name] = gradient.detach()\n",
    "\n",
    "model.add_hook(bwd_cache_filter, backward_cache_hook, \"bwd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to compute the metric\n",
    "def get_answer_logit(logits: Float[Tensor, \"batch pos d_vocab\"], clean_answers: Int[Tensor, \"batch\"],\n",
    "                        ansnwer_pos: Int[Tensor, \"batch\"], return_all_logits=False) -> Float[Tensor, \"batch\"]:\n",
    "    # clean_answers_pos_idx = clean_answers_pos.unsqueeze(-1).unsqueeze(-1).expand(-1, logits.size(1), logits.size(2))\n",
    "\n",
    "    answer_pos_idx = einops.repeat(ansnwer_pos, 'batch -> batch 1 d_vocab',\n",
    "                                    d_vocab=logits.shape[-1])\n",
    "    answer_logits = logits.gather(1, answer_pos_idx).squeeze(1) # shape [batch, d_vocab]\n",
    "\n",
    "    correct_logits = answer_logits.gather(1, clean_answers.unsqueeze(1)).squeeze(1) # shape [batch]\n",
    "\n",
    "    if return_all_logits:\n",
    "        return answer_logits, correct_logits\n",
    "\n",
    "    return correct_logits\n",
    "\n",
    "def get_logit_diff(logits: Float[Tensor, \"batch pos d_vocab\"],\n",
    "                clean_answers: Int[Tensor, \"batch\"], patched_answers: Int[Tensor, \"batch count\"],\n",
    "                answer_pos: Int[Tensor, \"batch\"], patch_answer_reduce='max') -> Float[Tensor, \"batch\"]:\n",
    "    # Compute the logits for the correct answers and the tokens they have been computed at (answer_logits)\n",
    "    answer_logits, correct_logits = get_answer_logit(logits, clean_answers, answer_pos, return_all_logits=True)\n",
    "\n",
    "    if patched_answers.dim() == 1:  # If there's only one incorrect answer, gather the incorrect answer logits\n",
    "        incorrect_logits = answer_logits.gather(1, patched_answers.unsqueeze(1)).squeeze(1)  # shape [batch]\n",
    "    else:\n",
    "        incorrect_logits = answer_logits.gather(1, patched_answers)  # shape [batch, answer_count]\n",
    "\n",
    "    # If there are multiple incorrect answer options, incorrect_logits is now of shape [batch, answer_count]\n",
    "    if patched_answers.dim() == 2:\n",
    "        # Sum the logits for each incorrect answer option\n",
    "        if patch_answer_reduce == 'sum':\n",
    "            incorrect_logits = incorrect_logits.sum(dim=1)\n",
    "        # Or take their maximum: this should be a better option to avoid situations where the model outputs gibberish and all the answers have similar logits\n",
    "        elif patch_answer_reduce == 'max':\n",
    "            incorrect_logits = incorrect_logits.max(dim=1).values\n",
    "\n",
    "    # Both logit tensors are now of shape [batch]\n",
    "    return incorrect_logits - correct_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['blocks.5.hook_resid_post.hook_sae_acts_post', 'blocks.14.hook_resid_post.hook_sae_acts_post', 'blocks.15.hook_resid_post.hook_sae_acts_post', 'blocks.15.hook_resid_post.hook_sae_error', 'blocks.16.hook_resid_post.hook_sae_acts_post', 'blocks.17.hook_mlp_out.hook_sae_acts_post', 'blocks.17.hook_resid_post.hook_sae_error', 'blocks.18.hook_resid_post.hook_sae_acts_post', 'blocks.18.hook_resid_post.hook_sae_error', 'blocks.19.attn.hook_z.hook_sae_acts_post', 'blocks.19.hook_mlp_out.hook_sae_acts_post', 'blocks.19.hook_resid_post.hook_sae_acts_post', 'blocks.19.hook_resid_post.hook_sae_error', 'blocks.20.hook_resid_post.hook_sae_acts_post', 'blocks.21.hook_mlp_out.hook_sae_acts_post', 'blocks.21.hook_resid_post.hook_sae_acts_post', 'blocks.22.hook_mlp_out.hook_sae_acts_post', 'blocks.22.hook_resid_post.hook_sae_acts_post', 'blocks.23.hook_resid_post.hook_sae_acts_post', 'blocks.24.hook_resid_post.hook_sae_acts_post', 'blocks.25.hook_resid_post.hook_sae_acts_post']),\n",
       " dict_keys(['blocks.25.hook_resid_post.hook_sae_acts_post', 'blocks.24.hook_resid_post.hook_sae_acts_post', 'blocks.23.hook_resid_post.hook_sae_acts_post', 'blocks.22.hook_resid_post.hook_sae_acts_post', 'blocks.22.hook_mlp_out.hook_sae_acts_post', 'blocks.21.hook_resid_post.hook_sae_acts_post', 'blocks.21.hook_mlp_out.hook_sae_acts_post', 'blocks.20.hook_resid_post.hook_sae_acts_post', 'blocks.19.hook_resid_post.hook_sae_error', 'blocks.19.hook_resid_post.hook_sae_acts_post', 'blocks.19.hook_mlp_out.hook_sae_acts_post', 'blocks.19.attn.hook_z.hook_sae_acts_post', 'blocks.18.hook_resid_post.hook_sae_error', 'blocks.18.hook_resid_post.hook_sae_acts_post', 'blocks.17.hook_resid_post.hook_sae_error', 'blocks.17.hook_mlp_out.hook_sae_acts_post', 'blocks.16.hook_resid_post.hook_sae_acts_post', 'blocks.15.hook_resid_post.hook_sae_error', 'blocks.15.hook_resid_post.hook_sae_acts_post']))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing the forward pass to get the caches\n",
    "metric_clean = lambda logits: get_logit_diff(logits, clean_answers, corrupted_answers, clean_answers_pos).mean()\n",
    "\n",
    "# Enable gradients only during the backward pass\n",
    "with torch.set_grad_enabled(True):\n",
    "    metric_value = metric_clean(sfc_model.model(clean_prompts, attention_mask=clean_attn_mask))\n",
    "    metric_value.backward()  # Compute gradients\n",
    "\n",
    "fwd_cache.keys(), bwd_cache.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " True,\n",
       " dict_keys(['blocks.5.hook_resid_post.hook_sae_acts_post', 'blocks.14.hook_resid_post.hook_sae_acts_post', 'blocks.15.hook_resid_post.hook_sae_error', 'blocks.15.hook_resid_post.hook_sae_acts_post', 'blocks.16.hook_resid_post.hook_sae_acts_post', 'blocks.17.hook_mlp_out.hook_sae_acts_post', 'blocks.17.hook_resid_post.hook_sae_error', 'blocks.18.hook_resid_post.hook_sae_error', 'blocks.18.hook_resid_post.hook_sae_acts_post', 'blocks.19.attn.hook_z.hook_sae_acts_post', 'blocks.19.hook_mlp_out.hook_sae_acts_post', 'blocks.19.hook_resid_post.hook_sae_error', 'blocks.19.hook_resid_post.hook_sae_acts_post', 'blocks.20.hook_resid_post.hook_sae_acts_post', 'blocks.21.hook_mlp_out.hook_sae_acts_post', 'blocks.21.hook_resid_post.hook_sae_acts_post', 'blocks.22.hook_mlp_out.hook_sae_acts_post', 'blocks.22.hook_resid_post.hook_sae_acts_post', 'blocks.23.hook_resid_post.hook_sae_acts_post', 'blocks.24.hook_resid_post.hook_sae_acts_post', 'blocks.25.hook_resid_post.hook_sae_acts_post']))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bwd_cache.keys() == adjacent_nodes.keys(), fwd_cache.keys() == filtered_nodes.keys(), filtered_nodes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('blocks.18.hook_resid_post.hook_sae_error', None),\n",
       "  ('blocks.18.hook_resid_post.hook_sae_acts_post', None),\n",
       "  ('blocks.19.attn.hook_z.hook_sae_acts_post', None),\n",
       "  ('blocks.19.hook_mlp_out.hook_sae_acts_post', None)],\n",
       " 'hook_resid_post',\n",
       " 19,\n",
       " True,\n",
       " torch.Size([8]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_parent = 'blocks.19.hook_resid_post.hook_sae_error'\n",
    "parent_metadata = adjacent_nodes_metadata[current_parent][0]\n",
    "\n",
    "parent_hook = parent_metadata['parent_hook']\n",
    "parent_layer = parent_metadata['parent_layer']\n",
    "is_parent_error = parent_metadata['is_parent_error']\n",
    "parent_mask = parent_metadata['parent_threshold_mask']\n",
    "\n",
    "adjacent_nodes[current_parent], parent_hook, parent_layer, is_parent_error, parent_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_parent_error:\n",
    "    # If the parent node is an error node, we need only one backward pass to get the gradients w.r.t. all the children nodes\n",
    "    # for child_name, _ in adjacent_nodes[current_parent]:\n",
    "    #     print(f\"Processing  {child_name}\")\n",
    "    #     child_metadata = [metadata for metadata in adjacent_nodes_metadata[current_parent] if metadata['child_name'] == child_name][0]\n",
    "    #     print(child_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_parent_error:\n",
    "    # If the parent node is a tensor of SAE latents, we'll need to perform a backward pass for each SAE latent above the threshold\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "taras_aisc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05d2736b761f40239f148ba84de8c2cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0df93b18ecfd479aa59a2f6a1add89c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "19087122473c430aa3255af99f1c8b77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe32bf79d13147fdae30a0055305bc69",
      "placeholder": "​",
      "style": "IPY_MODEL_c51c032beebd42a8874fa08c7d087eb8",
      "value": " 396/396 [00:00&lt;00:00, 30.2kB/s]"
     }
    },
    "1e35e267085f40c7b06499edb36398e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d27ae13a4442adabc1bdb42faa8dc8",
      "max": 396,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e615c58c65f48e4adf9ab6a4b320bbb",
      "value": 396
     }
    },
    "26f50b307e0341738600f67a3839c44c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39e26871b8f9439aa9f3ca4b10df7d32",
      "placeholder": "​",
      "style": "IPY_MODEL_32749fc365974bc0a975eae93680b3c3",
      "value": "config.json: 100%"
     }
    },
    "273d1195e6164099afdd02ca3a2b0f9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e2599eec26aa49b38840fd54a0d42a2e",
       "IPY_MODEL_502ec2273acf4149b25be5165d402583",
       "IPY_MODEL_e9533a2bed6448e7a199f3af58bf1893"
      ],
      "layout": "IPY_MODEL_99f5fe50d68244708acbc5e4a37230fc"
     }
    },
    "2793290613ec41d9bb99e7e19ef91c1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "29bb4262b88c46e59f7aaf116f8220ae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a4667c1fa3c43fa85911909ade4c208": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c47ec2e1e4044971b19dff538a4702f1",
      "placeholder": "​",
      "style": "IPY_MODEL_738e5b7d60d24f83bf2d1767a1fe1d99",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "2bf62dcce3c045ed8d8cca82112ce92f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e2a85b9842b44b6a58068aea133d7b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f3b97cb27124c649bf19d5146683959",
      "max": 567,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_69ff861b41a24c41b6b12eb5600c59e2",
      "value": 567
     }
    },
    "32749fc365974bc0a975eae93680b3c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35945bf1660d47a4ad4190e2bf796212": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "363fd297dd1e4d55b730dad9989bbe92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39e26871b8f9439aa9f3ca4b10df7d32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c1a2628c37648b4a50f12960d451011": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d782cab680442caa46845a856aafad8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78f73a468de847ad80ca04428b584187",
      "placeholder": "​",
      "style": "IPY_MODEL_ff07663f2ea6428297429b8ad8c5e6ad",
      "value": " 567/567 [00:00&lt;00:00, 40.8kB/s]"
     }
    },
    "4f58877f38ea480a86950c6efe373d1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_26f50b307e0341738600f67a3839c44c",
       "IPY_MODEL_2e2a85b9842b44b6a58068aea133d7b7",
       "IPY_MODEL_3d782cab680442caa46845a856aafad8"
      ],
      "layout": "IPY_MODEL_857b9874473e43729dab3f3bd240fd00"
     }
    },
    "5003e891806e496e9c38c3e242f8ef5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bf62dcce3c045ed8d8cca82112ce92f",
      "placeholder": "​",
      "style": "IPY_MODEL_c4cce6a3648f48ac9711f09c524637fb",
      "value": " 99.0/99.0 [00:00&lt;00:00, 6.40kB/s]"
     }
    },
    "502ec2273acf4149b25be5165d402583": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91a1a5929ed24ac4b261618f9e4457bb",
      "max": 2113710,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0df93b18ecfd479aa59a2f6a1add89c0",
      "value": 2113710
     }
    },
    "51c40169897a4c21be1f26f60588aa93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e9abfc3ca6a4d19bff1f159de63d64d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69ff861b41a24c41b6b12eb5600c59e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "70c4b6b0918c4cbdb452dd3d2a304a4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ead820b804bf465988abad58840605bc",
       "IPY_MODEL_7cf2a945b4fc48e0af2622163a35a484",
       "IPY_MODEL_a0afde3ad1a748e4bc5516c7c75ca04f"
      ],
      "layout": "IPY_MODEL_5e9abfc3ca6a4d19bff1f159de63d64d"
     }
    },
    "738e5b7d60d24f83bf2d1767a1fe1d99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78f73a468de847ad80ca04428b584187": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7cf2a945b4fc48e0af2622163a35a484": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3f1bf3eb1e245bd8bdfb4ecffc9c43d",
      "max": 166029852,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ca7f8fd7bbb41088cf4492e06b71027",
      "value": 166029852
     }
    },
    "7e615c58c65f48e4adf9ab6a4b320bbb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "857b9874473e43729dab3f3bd240fd00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85ea2672e549427bad5c82abeafcb4bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91a1a5929ed24ac4b261618f9e4457bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93ef2d5364cc431e8766c7207de28563": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96454b0ef34d4b56837f40f555ecfd4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c1a2628c37648b4a50f12960d451011",
      "max": 99,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c130fa85705c49bfbbf71674c78f2313",
      "value": 99
     }
    },
    "97cb7ad01ad04cf8b472fed392685075": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99f5fe50d68244708acbc5e4a37230fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ca7f8fd7bbb41088cf4492e06b71027": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d11e7abf8a04b8bbb84538880281f55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f3b97cb27124c649bf19d5146683959": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0afde3ad1a748e4bc5516c7c75ca04f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35945bf1660d47a4ad4190e2bf796212",
      "placeholder": "​",
      "style": "IPY_MODEL_363fd297dd1e4d55b730dad9989bbe92",
      "value": " 166M/166M [00:00&lt;00:00, 366MB/s]"
     }
    },
    "a3f1bf3eb1e245bd8bdfb4ecffc9c43d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4d27ae13a4442adabc1bdb42faa8dc8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2676bcd797f4505add2ab7f8bbf613b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b364f782c8df4864a270a02c2fa3d469": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_deaf4f52175c4230a417757425b8d9f4",
       "IPY_MODEL_96454b0ef34d4b56837f40f555ecfd4a",
       "IPY_MODEL_5003e891806e496e9c38c3e242f8ef5a"
      ],
      "layout": "IPY_MODEL_29bb4262b88c46e59f7aaf116f8220ae"
     }
    },
    "b519e34a8ac846c1bbe07fb0f7c47b40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a4667c1fa3c43fa85911909ade4c208",
       "IPY_MODEL_1e35e267085f40c7b06499edb36398e0",
       "IPY_MODEL_19087122473c430aa3255af99f1c8b77"
      ],
      "layout": "IPY_MODEL_05d2736b761f40239f148ba84de8c2cb"
     }
    },
    "c130fa85705c49bfbbf71674c78f2313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c47ec2e1e4044971b19dff538a4702f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4cce6a3648f48ac9711f09c524637fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c51c032beebd42a8874fa08c7d087eb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf249cfe1742424db91c27806810e6c4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "deaf4f52175c4230a417757425b8d9f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_85ea2672e549427bad5c82abeafcb4bd",
      "placeholder": "​",
      "style": "IPY_MODEL_93ef2d5364cc431e8766c7207de28563",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "e2599eec26aa49b38840fd54a0d42a2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf249cfe1742424db91c27806810e6c4",
      "placeholder": "​",
      "style": "IPY_MODEL_9d11e7abf8a04b8bbb84538880281f55",
      "value": "tokenizer.json: 100%"
     }
    },
    "e9533a2bed6448e7a199f3af58bf1893": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2676bcd797f4505add2ab7f8bbf613b",
      "placeholder": "​",
      "style": "IPY_MODEL_2793290613ec41d9bb99e7e19ef91c1c",
      "value": " 2.11M/2.11M [00:00&lt;00:00, 4.91MB/s]"
     }
    },
    "ead820b804bf465988abad58840605bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51c40169897a4c21be1f26f60588aa93",
      "placeholder": "​",
      "style": "IPY_MODEL_97cb7ad01ad04cf8b472fed392685075",
      "value": "model.safetensors: 100%"
     }
    },
    "fe32bf79d13147fdae30a0055305bc69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff07663f2ea6428297429b8ad8c5e6ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
